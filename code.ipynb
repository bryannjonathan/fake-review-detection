{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'rating', 'label', 'text_'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('fake_reviews_dataset.csv')\n",
    "\n",
    "df\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pre Processing - Cleanup the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\24bry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\24bry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               text_  \\\n",
      "0  Love this!  Well made, sturdy, and very comfor...   \n",
      "1  love it, a great upgrade from the original.  I...   \n",
      "2  This pillow saved my back. I love the look and...   \n",
      "3  Missing information on how to use it, but it i...   \n",
      "4  Very nice set. Good quality. We have had the s...   \n",
      "\n",
      "                                  cleaned_review  \n",
      "0  love ! well made sturdi comfort love ! pretti  \n",
      "1   love great upgrad origin ive mine coupl year  \n",
      "2         pillow save back love look feel pillow  \n",
      "3          miss inform use great product price !  \n",
      "4            nice set good qualiti set two month  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "\n",
    "    # Remove special characters, digits, and punctuation EXCEPT exclamation marks\n",
    "    text = re.sub(r'[^a-z\\s!]', '', text)  # Keep '!' for exclamation mark count\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Apply stemming (optional, depends on your model needs)\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Join words back into a string\n",
    "    cleaned_text = \" \".join(words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Example usage: Clean the 'text' column in the DataFrame\n",
    "# Apply the cleaning function to the 'text_' column\n",
    "df['cleaned_review'] = df['text_'].apply(clean_text)\n",
    "\n",
    "# Display the cleaned reviews alongside the original ones\n",
    "print(df[['text_', 'cleaned_review']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Engineering</h3>\n",
    "Contains:\n",
    "1. Review Length\n",
    "2. Sentiment Polarity\n",
    "3. Sentiment Subjectivity\n",
    "4. ! Count\n",
    "5. ? Count (maybe remove)\n",
    "6. All-Caps word count\n",
    "7. Superlative word count\n",
    "8. Unique-word ratio\n",
    "9. Rating score\n",
    "10. Category one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "\n",
    "# assume df is already loaded and has columns: \n",
    "#   'text_' (raw review), 'cleaned_review' (preprocessed text), \n",
    "#   'rating' (numeric), and 'category' (string)\n",
    "\n",
    "# 1. Review length (number of words in the cleaned text)\n",
    "df['review_length'] = df['cleaned_review'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# 2. Sentiment polarity (range: -1 to +1)\n",
    "df['sentiment_polarity'] = df['cleaned_review'].apply(\n",
    "    lambda x: TextBlob(x).sentiment.polarity\n",
    ")\n",
    "\n",
    "# 3. Sentiment subjectivity (range: 0 to 1)\n",
    "df['sentiment_subjectivity'] = df['cleaned_review'].apply(\n",
    "    lambda x: TextBlob(x).sentiment.subjectivity\n",
    ")\n",
    "\n",
    "# 4. Exclamation mark count (from raw text)\n",
    "df['exclamation_count'] = df['text_'].apply(lambda x: x.count('!'))\n",
    "\n",
    "# 5. Question mark count (from raw text)\n",
    "df['question_count'] = df['text_'].apply(lambda x: x.count('?'))\n",
    "\n",
    "# 6. All‑CAPS word count (indicates “shouting” or emphasis)\n",
    "df['allcaps_count'] = df['text_'].apply(\n",
    "    lambda txt: sum(1 for w in txt.split() if w.isupper() and len(w) > 1)\n",
    ")\n",
    "\n",
    "# 7. Superlative words count\n",
    "superlatives = ['best', 'worst', 'perfect', 'amazing', \n",
    "                'excellent', 'fantastic', 'unbelievable']\n",
    "df['superlative_count'] = df['cleaned_review'].apply(\n",
    "    lambda x: sum(1 for w in x.split() if w in superlatives)\n",
    ")\n",
    "\n",
    "# 8. Unique‑word ratio (lexical diversity)\n",
    "df['unique_word_ratio'] = df['cleaned_review'].apply(\n",
    "    lambda txt: len(set(txt.split())) / max(len(txt.split()), 1)\n",
    ")\n",
    "\n",
    "# 9. Rating score (use the star rating directly)\n",
    "df['rating_score'] = df['rating'].astype(float)\n",
    "\n",
    "# 10. Category one‑hot encoding\n",
    "df = pd.get_dummies(df, columns=['category'], prefix='cat')\n",
    "\n",
    "# At this point, df contains all engineered features alongside:\n",
    "#  - 'cleaned_review' (for TF‑IDF vectorization)\n",
    "#  - 'label'         (your target: real vs. fake)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   review_length  sentiment_polarity  sentiment_subjectivity  \\\n",
      "0              9               0.625                   0.600   \n",
      "1              8               0.650                   0.675   \n",
      "2              7               0.250                   0.300   \n",
      "3              7               1.000                   0.750   \n",
      "4              7               0.650                   0.800   \n",
      "\n",
      "   exclamation_count  question_count  allcaps_count  superlative_count  \\\n",
      "0                  2               0              0                  0   \n",
      "1                  0               0              0                  0   \n",
      "2                  0               0              0                  0   \n",
      "3                  1               0              0                  0   \n",
      "4                  0               0              0                  0   \n",
      "\n",
      "   unique_word_ratio  rating_score  \n",
      "0           0.777778           5.0  \n",
      "1           1.000000           5.0  \n",
      "2           0.857143           5.0  \n",
      "3           1.000000           1.0  \n",
      "4           0.857143           5.0  \n"
     ]
    }
   ],
   "source": [
    "print(df[['review_length',\n",
    "          'sentiment_polarity',\n",
    "          'sentiment_subjectivity',\n",
    "          'exclamation_count',\n",
    "          'question_count',\n",
    "          'allcaps_count',\n",
    "          'superlative_count',\n",
    "          'unique_word_ratio',\n",
    "          'rating_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>TF-IDF Vectorization of Cleand Review</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1) Vectorize text\n",
    "tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1,2), stop_words='english')\n",
    "X_text = tfidf.fit_transform(df['cleaned_review'])\n",
    "\n",
    "# 2) Stack engineered features\n",
    "numeric_cols = [\n",
    "    'review_length','sentiment_polarity','sentiment_subjectivity',\n",
    "    'exclamation_count','allcaps_count','superlative_count',\n",
    "    'unique_word_ratio','rating_score'\n",
    "]\n",
    "X_num = df[numeric_cols].values\n",
    "X = hstack([X_text, X_num])\n",
    "y = df['label'].values\n",
    "\n",
    "# Map the string labels to numeric\n",
    "df['y'] = df['label'].map({'OR': 0, 'CG': 1})\n",
    "\n",
    "# Stack your features into X as before\n",
    "X = hstack([X_text, X_num])\n",
    "\n",
    "#Pull the numeric target\n",
    "y = df['y'].values\n",
    "\n",
    "#Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using Random Forest</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        real       0.86      0.85      0.85      6065\n",
      "        fake       0.85      0.86      0.86      6065\n",
      "\n",
      "    accuracy                           0.85     12130\n",
      "   macro avg       0.85      0.85      0.85     12130\n",
      "weighted avg       0.85      0.85      0.85     12130\n",
      "\n",
      "Confusion matrix:\n",
      " [[5170  895]\n",
      " [ 864 5201]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) Initialize and train\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 3) Evaluate\n",
    "print(classification_report(y_test, y_pred, target_names=['Real (OR)','Fake (CG)']))\n",
    "\n",
    "# Optional: view confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Logistic Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 1) Initialize and train\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on test set\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "# 3) Evaluate\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=['Real (OR)','Fake (CG)']))\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "print(\"Confusion matrix:\\n\", cm_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Support Vector Machine (linear kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 1) Initialize and train\n",
    "svc = SVC(kernel='linear', probability=True, random_state=42, class_weight='balanced')\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on test set\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "# 3) Evaluate\n",
    "print(\"=== SVM (Linear Kernel) ===\")\n",
    "print(classification_report(y_test, y_pred_svc, target_names=['Real (OR)','Fake (CG)']))\n",
    "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"Confusion matrix:\\n\", cm_svc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XGB Boost</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: XGBoost Classifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# 1) Initialize and train\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum()\n",
    ")\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "# 2) Predict on test set\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# 3) Evaluate\n",
    "print(\"=== XGBoost ===\")\n",
    "print(classification_report(y_test, y_pred_xgb, target_names=['Real (OR)','Fake (CG)']))\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "print(\"Confusion matrix:\\n\", cm_xgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
